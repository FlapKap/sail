{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Convolutional Networks\n",
    "Are a network architecture described in the paper ‘An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling’\n",
    "In this notebook we demonstrate an application of this model on the adding problem, in an incremental setting. This is an adaptation of an experiment done in the original paper (The original model and adding experiment can be seen in the authors repository here: https://github.com/locuslab/TCN)\n",
    "\n",
    "### Reference\n",
    "Bai, Shaojie, J. Zico Kolter, and Vladlen Koltun. ‘An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling’. ArXiv:1803.01271 [Cs], 19 April 2018. http://arxiv.org/abs/1803.01271.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "Define the data generator as written in https://github.com/locuslab/TCN/blob/2f8c2b817050206397458dfd1f5a25ce8a32fe65/TCN/adding_problem/utils.py#L6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sail.models.torch.tcn import TCNRegressor\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def data_generator(N, seq_length):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seq_length: Length of the adding problem data\n",
    "        N: # of data in the set\n",
    "    \"\"\"\n",
    "    X_num = torch.rand([N, 1, seq_length])\n",
    "    X_mask = torch.zeros([N, 1, seq_length])\n",
    "    Y = torch.zeros([N, 1])\n",
    "    for i in range(N):\n",
    "        positions = np.random.choice(seq_length, size=2, replace=False)\n",
    "        X_mask[i, 0, positions[0]] = 1\n",
    "        X_mask[i, 0, positions[1]] = 1\n",
    "        Y[i,0] = X_num[i, 0, positions[0]] + X_num[i, 0, positions[1]]\n",
    "    X = torch.cat((X_num, X_mask), dim=1)\n",
    "    return Variable(X), Variable(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters. \n",
    "Everything is using same default values as original experiment. The only difference is the original experiment is batch learned, where we are incremental.\n",
    "Original experiment ran for 10 epochs of 50k samples. We run incrementally for 100k samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 2\n",
    "n_classes = 1\n",
    "batch_size = 30\n",
    "seq_length = 400\n",
    "#epochs = 10\n",
    "X_train, Y_train = data_generator(100000, seq_length)\n",
    "X_test, Y_test = data_generator(1000, seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "_TCN                                     [30, 2, 400]              [30, 1]                   --\n",
       "├─_TemporalConvNet: 1-1                  [30, 2, 400]              [30, 30, 400]             --\n",
       "│    └─Sequential: 2-1                   [30, 2, 400]              [30, 30, 400]             --\n",
       "│    │    └─_TemporalBlock: 3-1          [30, 2, 400]              [30, 30, 400]             6,930\n",
       "│    │    └─_TemporalBlock: 3-2          [30, 30, 400]             [30, 30, 400]             12,720\n",
       "│    │    └─_TemporalBlock: 3-3          [30, 30, 400]             [30, 30, 400]             12,720\n",
       "│    │    └─_TemporalBlock: 3-4          [30, 30, 400]             [30, 30, 400]             12,720\n",
       "│    │    └─_TemporalBlock: 3-5          [30, 30, 400]             [30, 30, 400]             12,720\n",
       "│    │    └─_TemporalBlock: 3-6          [30, 30, 400]             [30, 30, 400]             12,720\n",
       "│    │    └─_TemporalBlock: 3-7          [30, 30, 400]             [30, 30, 400]             12,720\n",
       "│    │    └─_TemporalBlock: 3-8          [30, 30, 400]             [30, 30, 400]             12,720\n",
       "├─_GAP1d: 1-2                            [30, 30, 400]             [30, 30]                  --\n",
       "│    └─AdaptiveAvgPool1d: 2-2            [30, 30, 400]             [30, 30, 1]               --\n",
       "│    └─Flatten: 2-3                      [30, 30, 1]               [30, 30]                  --\n",
       "├─Linear: 1-3                            [30, 30]                  [30, 1]                   31\n",
       "===================================================================================================================\n",
       "Total params: 96,001\n",
       "Trainable params: 96,001\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 95.45\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 70.99\n",
       "Params size (MB): 0.38\n",
       "Estimated Total Size (MB): 71.47\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: We use a very simple setting here (assuming all levels have the same # of channels.\n",
    "channel_sizes = [30]*8 \n",
    "kernel_size = 7\n",
    "dropout = 0.0\n",
    "\n",
    "learning_rate =4e-3\n",
    "\n",
    "tcn = TCNRegressor(input_channels,n_classes, layers=channel_sizes, ks=kernel_size, conv_dropout=dropout, fc_dropout=dropout, batch_size=batch_size)\n",
    "tcn.initialize()\n",
    "from torchinfo import summary\n",
    "summary(tcn.module_,X_train[:batch_size].shape,col_names=(\"input_size\",\"output_size\",\"num_params\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1807\u001b[0m  0.3524\n",
      "      2        \u001b[36m0.6894\u001b[0m  0.2986\n",
      "      3        \u001b[36m0.1889\u001b[0m  0.2893\n",
      "      4        0.1907  0.2817\n",
      "      5        0.2289  0.2767\n",
      "      6        \u001b[36m0.1686\u001b[0m  0.2668\n",
      "      7        0.2370  0.2688\n",
      "      8        0.1691  0.2690\n",
      "      9        0.3127  0.2751\n",
      "     10        0.2317  0.2742\n",
      "     11        0.2157  0.2851\n",
      "     12        0.2544  0.2825\n",
      "     13        \u001b[36m0.1575\u001b[0m  0.2706\n",
      "     14        \u001b[36m0.1449\u001b[0m  0.2734\n",
      "     15        0.2908  0.2836\n",
      "     16        0.2702  0.2730\n",
      "     17        \u001b[36m0.1157\u001b[0m  0.3574\n",
      "     18        0.1722  0.2762\n",
      "     19        0.2336  0.2716\n",
      "     20        0.2199  0.2924\n",
      "     21        \u001b[36m0.1084\u001b[0m  0.2787\n",
      "     22        0.1115  0.2756\n",
      "     23        0.2308  0.2749\n",
      "     24        0.2115  0.2876\n",
      "     25        0.1957  0.2737\n",
      "     26        0.2063  0.2696\n",
      "     27        0.1170  0.2794\n",
      "     28        0.2333  0.2854\n",
      "     29        0.1311  0.2877\n",
      "     30        0.2262  0.2817\n",
      "     31        0.1673  0.3140\n",
      "     32        0.2022  0.2783\n",
      "     33        0.1159  0.2946\n",
      "     34        0.1843  0.2778\n",
      "     35        0.1625  0.2793\n",
      "     36        0.1275  0.2896\n",
      "     37        0.2116  0.2847\n",
      "     38        0.2302  0.2722\n",
      "     39        0.1943  0.2695\n",
      "     40        0.2494  0.2736\n",
      "     41        0.1982  0.2718\n",
      "     42        0.1880  0.2719\n",
      "     43        0.2019  0.2725\n",
      "     44        0.2323  0.2722\n",
      "     45        0.2262  0.2719\n",
      "     46        0.2166  0.2692\n",
      "     47        \u001b[36m0.1013\u001b[0m  0.2712\n",
      "     48        0.1675  0.2694\n",
      "     49        0.1451  0.2735\n",
      "     50        0.1544  0.2723\n",
      "     51        0.1532  0.2730\n",
      "     52        0.1243  0.2716\n",
      "     53        0.1965  0.2728\n",
      "     54        0.1443  0.2706\n",
      "     55        0.2002  0.2683\n",
      "     56        0.2039  0.2725\n",
      "     57        0.1699  0.2722\n",
      "     58        0.1804  0.2727\n",
      "     59        0.1947  0.2698\n",
      "     60        0.1867  0.2709\n",
      "     61        0.1540  0.2752\n",
      "     62        0.1645  0.2751\n",
      "     63        0.1286  0.2739\n",
      "     64        0.1734  0.2907\n",
      "     65        0.1306  0.2930\n",
      "     66        0.2298  0.2922\n",
      "     67        0.1091  0.2694\n",
      "     68        0.1628  0.2683\n",
      "     69        0.1190  0.2702\n",
      "     70        \u001b[36m0.0816\u001b[0m  0.2675\n",
      "     71        0.1366  0.2674\n",
      "     72        0.1876  0.2670\n",
      "     73        0.1252  0.2680\n",
      "     74        0.1496  0.2690\n",
      "     75        0.1014  0.2766\n",
      "     76        0.1377  0.2769\n",
      "     77        0.1672  0.2716\n",
      "     78        0.1571  0.2830\n",
      "     79        0.1685  0.2971\n",
      "     80        0.1192  0.2895\n",
      "     81        0.2052  0.2815\n",
      "     82        0.1852  0.2790\n",
      "     83        0.1541  0.2952\n",
      "     84        0.1713  0.2794\n",
      "     85        0.1576  0.2787\n",
      "     86        0.1977  0.2833\n",
      "     87        0.1335  0.3054\n",
      "     88        0.1895  0.2883\n",
      "     89        0.1724  0.2903\n",
      "     90        0.2944  0.3047\n",
      "     91        0.2009  0.2774\n",
      "     92        0.1546  0.3356\n",
      "     93        0.2057  0.2887\n",
      "     94        0.1767  0.2663\n",
      "     95        0.1818  0.2772\n",
      "     96        0.1981  0.2776\n",
      "     97        0.2251  0.2694\n",
      "     98        0.1806  0.2703\n",
      "     99        0.1458  0.2664\n",
      "    100        0.1969  0.2956\n",
      "    101        0.1466  0.2877\n",
      "    102        0.1475  0.2841\n",
      "    103        0.3003  0.3063\n",
      "    104        0.1730  0.2872\n",
      "    105        0.1085  0.2827\n",
      "    106        0.1758  0.2768\n",
      "    107        0.2356  0.2765\n",
      "    108        0.1472  0.2770\n",
      "    109        0.2574  0.2941\n",
      "    110        0.1779  0.2810\n",
      "    111        0.1047  0.2822\n",
      "    112        0.1490  0.2690\n",
      "    113        0.1822  0.3340\n",
      "    114        0.2220  0.3056\n",
      "    115        0.2623  0.2695\n",
      "    116        0.1721  0.2733\n",
      "    117        0.1512  0.2764\n",
      "    118        0.1198  0.2952\n",
      "    119        0.1086  0.2821\n",
      "    120        0.1516  0.2947\n",
      "    121        0.1660  0.2871\n",
      "    123        0.1137  0.2926\n",
      "    124        0.1474  0.2834\n",
      "    125        0.1679  0.2850\n",
      "    126        0.2504  0.2996\n",
      "    127        0.1479  0.3206\n",
      "    128        0.1601  0.2833\n",
      "    129        0.1141  0.2851\n",
      "    130        0.1403  0.3234\n",
      "    131        0.2330  0.2807\n",
      "    132        0.1395  0.2818\n",
      "    133        0.1810  0.2751\n",
      "    134        0.1872  0.2694\n",
      "    135        0.1283  0.2784\n",
      "    136        0.1092  0.2782\n",
      "    137        0.1972  0.2822\n",
      "    138        0.1804  0.2875\n",
      "    139        0.1755  0.2751\n",
      "    140        0.1807  0.2770\n",
      "    141        0.1461  0.2753\n",
      "    142        0.1669  0.2769\n",
      "    143        0.1289  0.2754\n",
      "    144        0.2375  0.2769\n",
      "    145        0.1457  0.2794\n",
      "    146        0.1408  0.2751\n",
      "    147        0.1155  0.2779\n",
      "    148        0.1876  0.2807\n",
      "    149        0.1668  0.2805\n",
      "    150        0.2574  0.2793\n",
      "    151        0.1946  0.3079\n",
      "    152        0.1661  0.2795\n",
      "    153        0.1841  0.3133\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#optimizer = torch.optim.Adam(tcn.get_params(), lr=learning_rate)\n",
    "y_pred= []\n",
    "\n",
    "for i in range(0,X_train.size(0), batch_size):\n",
    "    if i + batch_size > X_train.size(0):\n",
    "        x, y = X_train[i:], Y_train[i:]\n",
    "    else:\n",
    "        x, y = X_train[i:(i+batch_size)], Y_train[i:(i+batch_size)]\n",
    "    tcn.partial_fit(x, y)\n",
    "    y_pred.append(tcn.predict(x)[0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/flapkap/Documents/git/sail/notebooks/tcn_adding_problem.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/flapkap/Documents/git/sail/notebooks/tcn_adding_problem.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss: \u001b[39m\u001b[39m{\u001b[39;00mtcn\u001b[39m.\u001b[39mget_loss(y_pred\u001b[39m=\u001b[39mtcn\u001b[39m.\u001b[39mpredict(X_test), y_true\u001b[39m=\u001b[39mY_test)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py:1503\u001b[0m, in \u001b[0;36mNeuralNet.get_loss\u001b[0;34m(self, y_pred, y_true, X, training)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1473'>1474</a>\u001b[0m \u001b[39m\"\"\"Return the loss for this batch.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1474'>1475</a>\u001b[0m \n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1475'>1476</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1499'>1500</a>\u001b[0m \n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1500'>1501</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1501'>1502</a>\u001b[0m y_true \u001b[39m=\u001b[39m to_tensor(y_true, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1502'>1503</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion_(y_pred, y_true)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/loss.py:520\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/loss.py?line=518'>519</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/loss.py?line=519'>520</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py:3101\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3096'>3097</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, target):\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3097'>3098</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3098'>3099</a>\u001b[0m         mse_loss, (\u001b[39minput\u001b[39m, target), \u001b[39minput\u001b[39m, target, size_average\u001b[39m=\u001b[39msize_average, reduce\u001b[39m=\u001b[39mreduce, reduction\u001b[39m=\u001b[39mreduction\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3099'>3100</a>\u001b[0m     )\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3100'>3101</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (target\u001b[39m.\u001b[39msize() \u001b[39m==\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msize()):\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3101'>3102</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3102'>3103</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3103'>3104</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3104'>3105</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize()),\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3105'>3106</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3106'>3107</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/functional.py?line=3107'>3108</a>\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "print(f\"loss: {tcn.get_loss(y_pred=tcn.predict(X_test), y_true=Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/flapkap/Documents/git/sail/notebooks/tcn_adding_problem.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flapkap/Documents/git/sail/notebooks/tcn_adding_problem.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph_objects\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgo\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flapkap/Documents/git/sail/notebooks/tcn_adding_problem.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/flapkap/Documents/git/sail/notebooks/tcn_adding_problem.ipynb#ch0000003?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss: \u001b[39m\u001b[39m{\u001b[39;00mtcn\u001b[39m.\u001b[39mget_loss(y_pred\u001b[39m=\u001b[39mtcn\u001b[39m.\u001b[39mpredict(X_train), y_true\u001b[39m=\u001b[39mY_test)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flapkap/Documents/git/sail/notebooks/tcn_adding_problem.ipynb#ch0000003?line=5'>6</a>\u001b[0m pio\u001b[39m.\u001b[39mrenderers\u001b[39m.\u001b[39mdefault \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvscode\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flapkap/Documents/git/sail/notebooks/tcn_adding_problem.ipynb#ch0000003?line=6'>7</a>\u001b[0m y_true \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mflatten()\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py:1470\u001b[0m, in \u001b[0;36mNeuralNet.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1439'>1440</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1440'>1441</a>\u001b[0m     \u001b[39m\"\"\"Where applicable, return class labels for samples in X.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1441'>1442</a>\u001b[0m \n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1442'>1443</a>\u001b[0m \u001b[39m    If the module's forward method returns multiple outputs as a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1467'>1468</a>\u001b[0m \n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1468'>1469</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1469'>1470</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py:1433\u001b[0m, in \u001b[0;36mNeuralNet.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1430'>1431</a>\u001b[0m nonlin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_predict_nonlinearity()\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1431'>1432</a>\u001b[0m y_probas \u001b[39m=\u001b[39m []\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1432'>1433</a>\u001b[0m \u001b[39mfor\u001b[39;00m yp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_iter(X, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1433'>1434</a>\u001b[0m     yp \u001b[39m=\u001b[39m yp[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(yp, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m yp\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1434'>1435</a>\u001b[0m     yp \u001b[39m=\u001b[39m nonlin(yp)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py:1279\u001b[0m, in \u001b[0;36mNeuralNet.forward_iter\u001b[0;34m(self, X, training, device)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1276'>1277</a>\u001b[0m iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(dataset, training\u001b[39m=\u001b[39mtraining)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1277'>1278</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m iterator:\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1278'>1279</a>\u001b[0m     yp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluation_step(batch, training\u001b[39m=\u001b[39;49mtraining)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1279'>1280</a>\u001b[0m     \u001b[39myield\u001b[39;00m to_device(yp, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py:1036\u001b[0m, in \u001b[0;36mNeuralNet.evaluation_step\u001b[0;34m(self, batch, training)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1033'>1034</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(training):\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1034'>1035</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_training(training)\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1035'>1036</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(Xi)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py:1359\u001b[0m, in \u001b[0;36mNeuralNet.infer\u001b[0;34m(self, x, **fit_params)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1356'>1357</a>\u001b[0m     x_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_x_and_fit_params(x, fit_params)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1357'>1358</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule_(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mx_dict)\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/skorch/net.py?line=1358'>1359</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule_(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/git/sail/sail/models/torch/tcn.py:123\u001b[0m, in \u001b[0;36m_TCN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/flapkap/Documents/git/sail/sail/models/torch/tcn.py?line=121'>122</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> <a href='file:///Users/flapkap/Documents/git/sail/sail/models/torch/tcn.py?line=122'>123</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtcn(x)\n\u001b[1;32m    <a href='file:///Users/flapkap/Documents/git/sail/sail/models/torch/tcn.py?line=123'>124</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgap(x)\n\u001b[1;32m    <a href='file:///Users/flapkap/Documents/git/sail/sail/models/torch/tcn.py?line=124'>125</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/git/sail/sail/models/torch/tcn.py:107\u001b[0m, in \u001b[0;36m_TemporalConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/flapkap/Documents/git/sail/sail/models/torch/tcn.py?line=105'>106</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> <a href='file:///Users/flapkap/Documents/git/sail/sail/models/torch/tcn.py?line=106'>107</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(x)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/git/sail/sail/models/torch/tcn.py:78\u001b[0m, in \u001b[0;36m_TemporalBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/flapkap/Documents/git/sail/sail/models/torch/tcn.py?line=76'>77</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='file:///Users/flapkap/Documents/git/sail/sail/models/torch/tcn.py?line=77'>78</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(x)\n\u001b[1;32m     <a href='file:///Users/flapkap/Documents/git/sail/sail/models/torch/tcn.py?line=78'>79</a>\u001b[0m     res \u001b[39m=\u001b[39m x \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample(x)\n\u001b[1;32m     <a href='file:///Users/flapkap/Documents/git/sail/sail/models/torch/tcn.py?line=79'>80</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out \u001b[39m+\u001b[39m res)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1120\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1116'>1117</a>\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1117'>1118</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[0;32m-> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1119'>1120</a>\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1120'>1121</a>\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1121'>1122</a>\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/conv.py:301\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=299'>300</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=300'>301</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/conv.py:297\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=292'>293</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=293'>294</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=294'>295</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=295'>296</a>\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=296'>297</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/imla/lib/python3.8/site-packages/torch/nn/modules/conv.py?line=297'>298</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'vscode'\n",
    "y_true = y.flatten().tolist()\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(x.size(0))), y=y_pred, name='predicted',\n",
    "                         line=dict(color='red', width=2)))\n",
    "fig.add_trace(go.Scatter(x=list(range(x.size(0))), y=y_true, name='actual',\n",
    "                         line=dict(color='blue', width=2)))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "305716b6135201a51f065ac030b02fe2ffabaacf91fbb6678831ef82ab0805ac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('imla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
