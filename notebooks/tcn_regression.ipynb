{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a0669e-3e1a-47a8-843e-bfe374f2379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehkj/miniconda3_i386/envs/imla/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from array import array\n",
    "from skmultiflow.data import RegressionGenerator\n",
    "from sail.models.torch.tcn import TCNRegressor\n",
    "from sail.models.torch.tcn import TCN\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade77e0e-8628-4902-8068-fcd62ca34fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 6000\n",
    "n_features = 12\n",
    "stream = RegressionGenerator(random_state=1,\n",
    "                             n_samples=n_samples,\n",
    "                             n_features=n_features)\n",
    "learner_tcn = TCNRegressor(c_in=n_features, c_out=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "398a53b9-30e0-47df-b954-aa8746285877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11           nan  0.0600\n",
      "     12           nan  0.0423\n",
      "     13           nan  0.0420\n",
      "     14           nan  0.0417\n",
      "     15           nan  0.0419\n",
      "     16           nan  0.0416\n",
      "     17           nan  0.0415\n",
      "     18           nan  0.0416\n",
      "     19           nan  0.0417\n",
      "     20           nan  0.0416\n",
      "     21           nan  0.0414\n",
      "     22           nan  0.0416\n",
      "     23           nan  0.0416\n",
      "     24           nan  0.0415\n",
      "     25           nan  0.0415\n",
      "     26           nan  0.0415\n",
      "     27           nan  0.0415\n",
      "     28           nan  0.0417\n",
      "     29           nan  0.0417\n",
      "     30           nan  0.0415\n",
      "     31           nan  0.0411\n",
      "     32           nan  0.0414\n",
      "     33           nan  0.0416\n",
      "     34           nan  0.0418\n",
      "     35           nan  0.0421\n",
      "     36           nan  0.0422\n",
      "     37           nan  0.0422\n",
      "     38           nan  0.0419\n",
      "     39           nan  0.0420\n",
      "     40           nan  0.0418\n",
      "     41           nan  0.0429\n",
      "     42           nan  0.0420\n",
      "     43           nan  0.0421\n",
      "     44           nan  0.0424\n",
      "     45           nan  0.0423\n",
      "     46           nan  0.0424\n",
      "     47           nan  0.0422\n",
      "     48           nan  0.0423\n",
      "     49           nan  0.0420\n",
      "     50           nan  0.0422\n",
      "     51           nan  0.0421\n",
      "     52           nan  0.0422\n",
      "     53           nan  0.0423\n",
      "     54           nan  0.0420\n",
      "     55           nan  0.0417\n",
      "     56           nan  0.0415\n",
      "     57           nan  0.0419\n",
      "     58           nan  0.0416\n",
      "     59           nan  0.0419\n",
      "     60           nan  0.0418\n",
      "     61           nan  0.0416\n",
      "     62           nan  0.0421\n",
      "     63           nan  0.0424\n",
      "     64           nan  0.0422\n",
      "     65           nan  0.0423\n",
      "     66           nan  0.0420\n",
      "     67           nan  0.0417\n",
      "     68           nan  0.0417\n",
      "     69           nan  0.0421\n",
      "     70           nan  0.0425\n",
      "     71           nan  0.0420\n",
      "     72           nan  0.0420\n",
      "     73           nan  0.0424\n",
      "     74           nan  0.0419\n",
      "     75           nan  0.0415\n",
      "     76           nan  0.0417\n",
      "     77           nan  0.0419\n",
      "     78           nan  0.0419\n",
      "     79           nan  0.0418\n",
      "     80           nan  0.0418\n",
      "     81           nan  0.0413\n",
      "     82           nan  0.0416\n",
      "     83           nan  0.0418\n",
      "     84           nan  0.0420\n",
      "     85           nan  0.0420\n",
      "     86           nan  0.0422\n",
      "     87           nan  0.0421\n",
      "     88           nan  0.0419\n",
      "     89           nan  0.0416\n",
      "     90           nan  0.0420\n",
      "     91           nan  0.0424\n",
      "     92           nan  0.0422\n",
      "     93           nan  0.0426\n",
      "     94           nan  0.0417\n",
      "     95           nan  0.0415\n",
      "     96           nan  0.0417\n",
      "     97           nan  0.0418\n",
      "     98           nan  0.0428\n",
      "     99           nan  0.0423\n",
      "    100           nan  0.0453\n",
      "    101           nan  0.0417\n",
      "    102           nan  0.0424\n",
      "    103           nan  0.0421\n",
      "    104           nan  0.0420\n",
      "    105           nan  0.0431\n",
      "    106           nan  0.0421\n",
      "    107           nan  0.0419\n",
      "    108           nan  0.0418\n",
      "    109           nan  0.0416\n",
      "    110           nan  0.0416\n",
      "    111           nan  0.0415\n",
      "    112           nan  0.0417\n",
      "    113           nan  0.0416\n",
      "    114           nan  0.0418\n",
      "    115           nan  0.0418\n",
      "    116           nan  0.0416\n",
      "    117           nan  0.0419\n",
      "    118           nan  0.0423\n",
      "    119           nan  0.0433\n",
      "    120           nan  0.0418\n",
      "    121           nan  0.0419\n",
      "    122           nan  0.0437\n",
      "    123           nan  0.0421\n",
      "    124           nan  0.0439\n",
      "    125           nan  0.0421\n",
      "    126           nan  0.0421\n",
      "    127           nan  0.0419\n",
      "    128           nan  0.0420\n",
      "    129           nan  0.0421\n",
      "    130           nan  0.0428\n",
      "    131           nan  0.0418\n",
      "    132           nan  0.0422\n",
      "    133           nan  0.0418\n",
      "    134           nan  0.0420\n",
      "    135           nan  0.0417\n",
      "    136           nan  0.0417\n",
      "    137           nan  0.0417\n",
      "    138           nan  0.0420\n",
      "    139           nan  0.0423\n",
      "    140           nan  0.0430\n",
      "    141           nan  0.0419\n",
      "    143           nan  0.0425\n",
      "    144           nan  0.0417\n",
      "    145           nan  0.0419\n",
      "    146           nan  0.0419\n",
      "    147           nan  0.0420\n",
      "    148           nan  0.0419\n",
      "    149           nan  0.0416\n",
      "    150           nan  0.0416\n",
      "    151           nan  0.0417\n",
      "    152           nan  0.0419\n",
      "    153           nan  0.0421\n",
      "    154           nan  0.0420\n",
      "    155           nan  0.0415\n",
      "    156           nan  0.0418\n",
      "    157           nan  0.0417\n",
      "    158           nan  0.0418\n",
      "    159           nan  0.0418\n",
      "    160           nan  0.0425\n",
      "    161           nan  0.0417\n",
      "    162           nan  0.0420\n",
      "    163           nan  0.0418\n",
      "    164           nan  0.0419\n",
      "    165           nan  0.0417\n",
      "    166           nan  0.0419\n",
      "    167           nan  0.0419\n",
      "    168           nan  0.0421\n",
      "    169           nan  0.0420\n",
      "    170           nan  0.0447\n",
      "    171           nan  0.0414\n",
      "    172           nan  0.0419\n",
      "    173           nan  0.0418\n",
      "    174           nan  0.0419\n",
      "    175           nan  0.0424\n",
      "    176           nan  0.0423\n",
      "    177           nan  0.0422\n",
      "    178           nan  0.0420\n",
      "    179           nan  0.0421\n",
      "    180           nan  0.0420\n",
      "    181           nan  0.0434\n",
      "    182           nan  0.0425\n",
      "    183           nan  0.0421\n",
      "    184           nan  0.0421\n",
      "    185           nan  0.0418\n",
      "    186           nan  0.0417\n",
      "    187           nan  0.0418\n",
      "    188           nan  0.0419\n",
      "    189           nan  0.0418\n",
      "    190           nan  0.0416\n",
      "    191           nan  0.0415\n",
      "    192           nan  0.0418\n",
      "    193           nan  0.0419\n",
      "    194           nan  0.0418\n",
      "    195           nan  0.0418\n",
      "    196           nan  0.0416\n",
      "    197           nan  0.0417\n",
      "    198           nan  0.0417\n",
      "    199           nan  0.0419\n",
      "    200           nan  0.0421\n",
      "    201           nan  0.0415\n",
      "    202           nan  0.0418\n",
      "    203           nan  0.0417\n",
      "    204           nan  0.0414\n",
      "    205           nan  0.0423\n",
      "    206           nan  0.0417\n",
      "    207           nan  0.0418\n",
      "    208           nan  0.0418\n",
      "    209           nan  0.0418\n",
      "    210           nan  0.0415\n",
      "    211           nan  0.0416\n",
      "    212           nan  0.0417\n",
      "    213           nan  0.0419\n",
      "    214           nan  0.0418\n",
      "    215           nan  0.0418\n",
      "    216           nan  0.0441\n",
      "    217           nan  0.0447\n",
      "    218           nan  0.0449\n",
      "    219           nan  0.0450\n",
      "    220           nan  0.0455\n",
      "    221           nan  0.0444\n",
      "    222           nan  0.0426\n",
      "    223           nan  0.0417\n",
      "    224           nan  0.0419\n",
      "    225           nan  0.0417\n",
      "    226           nan  0.0445\n",
      "    227           nan  0.0418\n",
      "    228           nan  0.0421\n",
      "    229           nan  0.0419\n",
      "    230           nan  0.0418\n",
      "    231           nan  0.0415\n",
      "    232           nan  0.0418\n",
      "    233           nan  0.0419\n",
      "    234           nan  0.0418\n",
      "    235           nan  0.0418\n",
      "    236           nan  0.0416\n",
      "    237           nan  0.0418\n",
      "    238           nan  0.0420\n",
      "    239           nan  0.0420\n",
      "    240           nan  0.0417\n",
      "    241           nan  0.0418\n",
      "    242           nan  0.0419\n",
      "    243           nan  0.0420\n",
      "    244           nan  0.0419\n",
      "    245           nan  0.0417\n",
      "    246           nan  0.0416\n",
      "    247           nan  0.0419\n",
      "    248           nan  0.0417\n",
      "    249           nan  0.0419\n",
      "    250           nan  0.0420\n",
      "    251           nan  0.0431\n",
      "    252           nan  0.0438\n",
      "    253           nan  0.0419\n",
      "    254           nan  0.0416\n",
      "    255           nan  0.0415\n",
      "    256           nan  0.0418\n",
      "    257           nan  0.0418\n",
      "    258           nan  0.0423\n",
      "    259           nan  0.0436\n",
      "    260           nan  0.0420\n",
      "    261           nan  0.0421\n",
      "    262           nan  0.0422\n",
      "    263           nan  0.0419\n",
      "    264           nan  0.0420\n",
      "    265           nan  0.0417\n",
      "    266           nan  0.0426\n",
      "    267           nan  0.0421\n",
      "    268           nan  0.0419\n",
      "    269           nan  0.0420\n",
      "    270           nan  0.0420\n",
      "    271           nan  0.0432\n",
      "    272           nan  0.0418\n",
      "    273           nan  0.0433\n",
      "    274           nan  0.0417\n",
      "    275           nan  0.0418\n",
      "    276           nan  0.0416\n",
      "    277           nan  0.0418\n",
      "    278           nan  0.0415\n",
      "    279           nan  0.0417\n",
      "    280           nan  0.0416\n",
      "    281           nan  0.0416\n",
      "    282           nan  0.0418\n",
      "    283           nan  0.0418\n",
      "    284           nan  0.0425\n",
      "    285           nan  0.0426\n",
      "    286           nan  0.0431\n",
      "    287           nan  0.0465\n",
      "    288           nan  0.0510\n",
      "    289           nan  0.0475\n",
      "    290           nan  0.0432\n",
      "    291           nan  0.0416\n",
      "    292           nan  0.0421\n",
      "    293           nan  0.0423\n",
      "    294           nan  0.0442\n",
      "    295           nan  0.0421\n",
      "    296           nan  0.0419\n",
      "    297           nan  0.0420\n",
      "    298           nan  0.0423\n",
      "    299           nan  0.0421\n",
      "    300           nan  0.0421\n",
      "    301           nan  0.0443\n",
      "    302           nan  0.0428\n",
      "    303           nan  0.0422\n",
      "    304           nan  0.0419\n",
      "    305           nan  0.0418\n",
      "    306           nan  0.0419\n",
      "    307           nan  0.0419\n",
      "    308           nan  0.0417\n",
      "    309           nan  0.0417\n",
      "    310           nan  0.0435\n",
      "    311           nan  0.0417\n",
      "    312           nan  0.0418\n",
      "    313           nan  0.0419\n",
      "    314           nan  0.0417\n",
      "    315           nan  0.0418\n",
      "    316           nan  0.0416\n",
      "    317           nan  0.0420\n",
      "    318           nan  0.0421\n",
      "    319           nan  0.0426\n",
      "    320           nan  0.0428\n",
      "    321           nan  0.0419\n",
      "    322           nan  0.0424\n",
      "    323           nan  0.0420\n",
      "    324           nan  0.0424\n",
      "    325           nan  0.0419\n",
      "    326           nan  0.0424\n",
      "    327           nan  0.0420\n",
      "    328           nan  0.0422\n",
      "    329           nan  0.0421\n",
      "    330           nan  0.0420\n",
      "    331           nan  0.0415\n",
      "    332           nan  0.0421\n",
      "    333           nan  0.0422\n",
      "    334           nan  0.0452\n",
      "    335           nan  0.0426\n",
      "    336           nan  0.0426\n",
      "    337           nan  0.0424\n",
      "    338           nan  0.0427\n",
      "    339           nan  0.0428\n",
      "    340           nan  0.0420\n",
      "    341           nan  0.0415\n",
      "    342           nan  0.0417\n",
      "    343           nan  0.0423\n",
      "    344           nan  0.0419\n",
      "    345           nan  0.0420\n",
      "    346           nan  0.0423\n",
      "    347           nan  0.0423\n",
      "    348           nan  0.0421\n",
      "    349           nan  0.0421\n",
      "    350           nan  0.0421\n",
      "    351           nan  0.0423\n",
      "    352           nan  0.0422\n",
      "    353           nan  0.0423\n",
      "    354           nan  0.0418\n",
      "    355           nan  0.0422\n",
      "    356           nan  0.0421\n",
      "    357           nan  0.0425\n",
      "    358           nan  0.0419\n",
      "    359           nan  0.0422\n",
      "    360           nan  0.0423\n",
      "    361           nan  0.0416\n",
      "    362           nan  0.0421\n",
      "    363           nan  0.0421\n",
      "    364           nan  0.0422\n",
      "    365           nan  0.0444\n",
      "    366           nan  0.0422\n",
      "    367           nan  0.0426\n",
      "    368           nan  0.0427\n",
      "    369           nan  0.0423\n",
      "    370           nan  0.0423\n",
      "    371           nan  0.0418\n",
      "    372           nan  0.0422\n",
      "    373           nan  0.0419\n",
      "    374           nan  0.0421\n",
      "    375           nan  0.0419\n",
      "    376           nan  0.0425\n",
      "    377           nan  0.0422\n",
      "    378           nan  0.0423\n",
      "    379           nan  0.0421\n",
      "    380           nan  0.0422\n",
      "    381           nan  0.0421\n",
      "    382           nan  0.0419\n",
      "    383           nan  0.0425\n",
      "    384           nan  0.0425\n",
      "    385           nan  0.0421\n",
      "    386           nan  0.0426\n",
      "    387           nan  0.0419\n",
      "    388           nan  0.0424\n",
      "    389           nan  0.0422\n",
      "    390           nan  0.0423\n",
      "    391           nan  0.0417\n",
      "    392           nan  0.0424\n",
      "    393           nan  0.0417\n",
      "    394           nan  0.0417\n",
      "    395           nan  0.0452\n",
      "    396           nan  0.0423\n",
      "    397           nan  0.0425\n",
      "    398           nan  0.0421\n",
      "    399           nan  0.0424\n",
      "    400           nan  0.0420\n",
      "    401           nan  0.0429\n",
      "    402           nan  0.0429\n",
      "    403           nan  0.0427\n",
      "    404           nan  0.0425\n",
      "    405           nan  0.0428\n",
      "    406           nan  0.0425\n",
      "    407           nan  0.0420\n",
      "    408           nan  0.0421\n",
      "    409           nan  0.0423\n",
      "    410           nan  0.0426\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     i \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     22\u001b[0m learner_tcn\u001b[38;5;241m.\u001b[39mpartial_fit(X, y)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mlearner_tcn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3_i386/envs/imla/lib/python3.8/site-packages/skorch/net.py:1470\u001b[0m, in \u001b[0;36mNeuralNet.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;124;03m\"\"\"Where applicable, return class labels for samples in X.\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m \n\u001b[1;32m   1443\u001b[0m \u001b[38;5;124;03m    If the module's forward method returns multiple outputs as a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1468\u001b[0m \n\u001b[1;32m   1469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3_i386/envs/imla/lib/python3.8/site-packages/skorch/net.py:1433\u001b[0m, in \u001b[0;36mNeuralNet.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1431\u001b[0m nonlin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_predict_nonlinearity()\n\u001b[1;32m   1432\u001b[0m y_probas \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1433\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m yp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_iter(X, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1434\u001b[0m     yp \u001b[38;5;241m=\u001b[39m yp[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(yp, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m yp\n\u001b[1;32m   1435\u001b[0m     yp \u001b[38;5;241m=\u001b[39m nonlin(yp)\n",
      "File \u001b[0;32m~/miniconda3_i386/envs/imla/lib/python3.8/site-packages/skorch/net.py:1279\u001b[0m, in \u001b[0;36mNeuralNet.forward_iter\u001b[0;34m(self, X, training, device)\u001b[0m\n\u001b[1;32m   1277\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(dataset, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m-> 1279\u001b[0m     yp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m to_device(yp, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3_i386/envs/imla/lib/python3.8/site-packages/skorch/net.py:1035\u001b[0m, in \u001b[0;36mNeuralNet.evaluation_step\u001b[0;34m(self, batch, training)\u001b[0m\n\u001b[1;32m   1033\u001b[0m Xi, _ \u001b[38;5;241m=\u001b[39m unpack_data(batch)\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(training):\n\u001b[0;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(Xi)\n",
      "File \u001b[0;32m~/miniconda3_i386/envs/imla/lib/python3.8/site-packages/skorch/net.py:842\u001b[0m, in \u001b[0;36mNeuralNet._set_training\u001b[0;34m(self, training)\u001b[0m\n\u001b[1;32m    840\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m--> 842\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3_i386/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1717\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1717\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3_i386/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1717\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1717\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "    \u001b[0;31m[... skipping similar frames: Module.train at line 1717 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3_i386/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1717\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1717\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3_i386/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining mode is expected to be boolean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m-> 1716\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m   1717\u001b[0m     module\u001b[38;5;241m.\u001b[39mtrain(mode)\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3_i386/envs/imla/lib/python3.8/site-packages/torch/nn/modules/module.py:1603\u001b[0m, in \u001b[0;36mModule.children\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchildren\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns an iterator over immediate children modules.\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m \n\u001b[1;32m   1600\u001b[0m \u001b[38;5;124;03m    Yields:\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;124;03m        Module: a child module\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1603\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m   1604\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m module\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "y_true = array('d')\n",
    "y_pred = array('d')\n",
    "index = []\n",
    "i = 0\n",
    "wait_samples = 10\n",
    "while cnt < n_samples and stream.has_more_samples():\n",
    "    X, y = stream.next_sample(batch_size=wait_samples)\n",
    "    y = np.array(y)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], -1)\n",
    "    y = y.reshape(y.shape[0], -1)\n",
    "    X = X.astype(np.float32)\n",
    "    y = y.astype(np.float32)\n",
    "\n",
    "    # Test every n samples\n",
    "    if (cnt % wait_samples == 0) & (cnt != 0):\n",
    "        y_true.append(y[0])\n",
    "        y_pred1 = learner_tcn.predict(X)[0][0]\n",
    "        y_pred.append(y_pred1)\n",
    "        index.append(i)\n",
    "        i = i + 1\n",
    "    learner_tcn.partial_fit(X, y)\n",
    "    learner_tcn.predict(X)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262bc28-e901-4a71-910d-c4b0fea6b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "y_pred = y_pred.tolist()\n",
    "y_true = y_true.tolist()\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=index, y=y_pred, name='predicted',\n",
    "                         line=dict(color='red', width=2)))\n",
    "fig.add_trace(go.Scatter(x=index, y=y_true, name='actual',\n",
    "                         line=dict(color='blue', width=2)))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
